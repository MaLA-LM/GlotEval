{
  "model_args": {
    "device": "cuda",
    "tensor_parallel_size": 4,
    "batch_size": 1,
    "dtype": "auto",
    "max_num_seqs": 256,
    "sampling_params": {
      "temperature": 0.0,
      "max_tokens": 2048
    }
  },

  "dev_max_samples": null,

  "prompt_language_strategy": "single",
  "prompt_language": "eng_Latn",

  "benchmark_params": {
    "benchmax_rule_based": {
      "seed": 42
    }
  },

  "prompt_guidelines": {
    "translation": {
      "required_placeholders": ["{src_text}", "{tgt_lang}"],
      "optional_placeholders": ["{src_lang}"],
      "description": "For translation tasks, the instruction template must include {src_text} and {tgt_lang}. {src_lang} is optional."
    },
    "classification": {
      "required_placeholders": ["{text}"],
      "optional_placeholders": [],
      "description": "For classification tasks, the instruction template must include {text}."
    },
    "summarization": {
      "required_placeholders": ["{text}"],
      "optional_placeholders": [],
      "description": "For summarization tasks, the instruction template must include {text}."
    },
    "open_generation": {
      "required_placeholders": ["{text}"],
      "optional_placeholders": [],
      "description": "For open generation tasks, must include {text} in your instruction."
    },
    "comprehension": {
      "required_placeholders": ["{question}", "{options}"],
      "optional_placeholders": ["{answer}"],
      "description": "For multiple-choice QA tasks, must include {question} and {options} placeholders. Optional to have {answer} in few-shot portion."
    },
    "token_classification": {
      "required_placeholders": ["{sentence}", "{token}", "{candidate_labels}"],
      "optional_placeholders": [],
      "description": "For token classification tasks, must have {sentence}, {token}, {candidate_labels} placeholders."
    },
    "nll": {
      "required_placeholders": ["{text}"],
      "optional_placeholders": [],
      "description": "For negative log-likelihood tasks, must have {text} placeholder."
    }
  }
}